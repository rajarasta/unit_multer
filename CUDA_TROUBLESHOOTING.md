# ğŸ”§ CUDA Structured Text + LLM Troubleshooting Guide

## â— GreÅ¡ka: JSON Parsing + Connection Refused

Ako vidite greÅ¡ke poput:
```
ğŸ’¡ Structured text analysis failed: SyntaxError: Expected ',' or ']' after array element in JSON
POST http://10.39.35.136:1234/v1/chat/completions net::ERR_CONNECTION_REFUSED
```

## ğŸ¯ Uzrok Problema

**Glavni uzrok:** CUDA LLM server nije pokrenut ili app koristi pogreÅ¡an endpoint.

**Sekundaran uzrok:** LLM vraÄ‡a malformed JSON response.

## ğŸ”§ Korak-po-korak ReÅ¡avanje

### 1. âœ… Proverite Odabir Analysis Mode

U Invoice Processing tab-u, proverite da li ste odabrali:
```
"Strukturirani tekst + CUDA LLM (optimiziran)"
```

**NAPOMENA:** Ako koristite bilo koji drugi mode (Spatial, Vision, itd.), biÄ‡e koriÅ¡ten stari endpoint `http://10.39.35.136:1234`.

### 2. ğŸš€ Pokrenite CUDA LLM Server

```bash
# U Command Prompt:
cd "E:\UI REFACTOR\aluminum-store-ui"
start_cuda_llm.bat
```

**SaÄekajte 2-5 minuta** da se model uÄita u memoriju. RTX 4060 moÅ¾e potrajati.

### 3. ğŸ§ª Testirajte Server

```bash
test_cuda_server.bat
```

Trebalo bi videti:
```
âœ… CUDA LLM server je dostupan i radi!
ğŸ“¡ Endpoint: http://127.0.0.1:8000/v1/chat/completions
ğŸ¯ Model: gpt-oss-20b
ğŸ” API Key: local-key
```

### 4. âš™ï¸ Konfiguracija u UI

U Invoice Processing â†’ Analysis Mode â†’ **STRUCTURED_TEXT**:

- **Server URL:** `http://127.0.0.1:8000/v1/chat/completions`
- **Model Alias:** `gpt-oss-20b`  
- **API Key:** `local-key`

### 5. ğŸ“„ Test sa Sample Document

Upload `test_sample.txt` i proverite da li radi.

## ğŸ” Detaljno Debugging

### A. Proverite Server Status

```bash
netstat -an | findstr :8000
```

Treba da vidite: `TCP 127.0.0.1:8000 ... LISTENING`

### B. Manual CURL Test

```bash
curl -X POST http://127.0.0.1:8000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer local-key" \
  -d "{\"model\":\"gpt-oss-20b\",\"messages\":[{\"role\":\"user\",\"content\":\"Test\"}],\"temperature\":0.1}"
```

### C. Proverite Model Path

U `start_cuda_llm.bat`, proverite:
```batch
set MODEL_PATH=E:\Modeli\gpt-oss-20b-MXFP4.gguf
```

**Promenite path** da odgovara vaÅ¡em modelu!

## ğŸš¨ ÄŒesti Problemi

| Problem | Uzrok | ReÅ¡enje |
|---------|-------|---------|
| `ERR_CONNECTION_REFUSED` | Server nije pokrenut | Pokrenite `start_cuda_llm.bat` |
| `Model not found` | PogreÅ¡an model path | AÅ¾urirajte MODEL_PATH u .bat file-u |
| `JSON parse error` | LLM vraÄ‡a malformed JSON | Smanite temperature ili promenite prompt |
| `401 Unauthorized` | PogreÅ¡an API key | Proverite da API key = "local-key" |
| `Port already in use` | Port 8000 zauzet | Ubijte proces ili promenite port |

## ğŸ¯ Optimizacije

### CUDA Performance

```batch
# U start_cuda_llm.bat:
--n_gpu_layers -1          # Svi layeri na GPU
--n_ctx 16384             # 16K context window  
--flash_attn 1            # Flash attention
--n_threads 8             # CPU threads za RTX 4060
```

### JSON Response Quality

- **Temperature:** 0.1-0.2 (niÅ¾e = strukturiranije)
- **Max Tokens:** 1200 (dovoljno za JSON response)
- **Response Format:** `{"type": "json_object"}` (forsiraj JSON)

## âœ… Verifikacija UspeÅ¡ne Konfiguracije

Kada sve radi, trebalo bi videti u konzoli:

```javascript
ğŸ” CUDA LLM server (http://127.0.0.1:8000/v1/chat/completions) accessible
âš¡ OCR/parsing + CUDA-optimiziran LLM: completed successfully
ğŸ¯ Model: gpt-oss-20b, Context: 16384, Extraction: 247 elements
```

## ğŸ“ PodrÅ¡ka

Ako problemi i dalje postoje:

1. **Proverite Windows Event Viewer** za sistemske greÅ¡ke
2. **Monitor Task Manager** za memoriju/GPU usage podczas loading
3. **Proverite firewall** da li blokira port 8000
4. **Restartujte sistem** ako je potrebno

---

ğŸ’¡ **TIP:** CUDA LLM setup traje 10-15 minuta prvi put, ali je nakon toga blazingly fast!