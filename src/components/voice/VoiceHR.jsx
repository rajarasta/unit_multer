import React, { useState, useRef, useCallback, useEffect } from 'react';
import { Mic, MicOff, Volume2, VolumeX, Loader, AlertCircle, CheckCircle } from 'lucide-react';

/**
 * Croatian Voice Interface with OpenAI Realtime API support
 * 
 * Features:
 * - Web Speech API fallback for quick testing
 * - OpenAI Realtime API (WebRTC) for production
 * - Croatian language optimized
 * - Voice activity detection
 * - Audio visualization
 */

const CROATIAN_VOICE_COMMANDS = {
  send: ['po≈°alji', 'posalji', '≈°alji', 'salji', 'uploadaj', 'obradi'],
  select: ['odaberi', 'izaberi', 'naƒëi', 'pronadi', 'otvori', 'poka≈æi'],
  confirm: ['jasan zvuk', 'potvrdi', 'da', 'mo≈æe', 'ajde'],
  cancel: ['poni≈°ti', 'odustani', 'stop', 'ne'],
  help: ['pomoƒá', 'help', '≈°to mogu'],
  newest: ['najnoviji', 'zadnji', 'najnoviji dokument']
};

export default function VoiceHR({ onCommand, onTranscript, onError, disabled = false }) {
  // State
  const [isListening, setIsListening] = useState(false);
  const [isProcessing, setIsProcessing] = useState(false);
  const [transcript, setTranscript] = useState('');
  const [confidence, setConfidence] = useState(0);
  const [mode, setMode] = useState('webspeech'); // 'webspeech' | 'realtime'
  const [audioLevel, setAudioLevel] = useState(0);
  const [realtimeConnected, setRealtimeConnected] = useState(false);
  const [lastCommand, setLastCommand] = useState(null);

  // Refs
  const recognitionRef = useRef(null);
  const realtimeRef = useRef(null);
  const audioContextRef = useRef(null);
  const analyserRef = useRef(null);
  const micStreamRef = useRef(null);
  const animationRef = useRef(null);

  // Initialize Web Speech API
  useEffect(() => {
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    
    if (SpeechRecognition) {
      const recognition = new SpeechRecognition();
      recognition.continuous = false;
      recognition.interimResults = true;
      recognition.lang = 'hr-HR';
      recognition.maxAlternatives = 3;
      
      recognition.onstart = () => {
        console.log('üé§ Web Speech recognition started');
        setIsListening(true);
      };
      
      recognition.onresult = (event) => {
        let finalTranscript = '';
        let interimTranscript = '';
        let bestConfidence = 0;
        
        for (let i = event.resultIndex; i < event.results.length; i++) {
          const result = event.results[i];
          const text = result[0].transcript;
          const conf = result[0].confidence;
          
          if (result.isFinal) {
            finalTranscript += text;
            bestConfidence = Math.max(bestConfidence, conf);
          } else {
            interimTranscript += text;
          }
        }
        
        const fullTranscript = finalTranscript || interimTranscript;
        setTranscript(fullTranscript);
        setConfidence(bestConfidence || 0.5);
        
        if (onTranscript) {
          onTranscript({ text: fullTranscript, confidence: bestConfidence, isFinal: !!finalTranscript });
        }
        
        // Process final transcript
        if (finalTranscript) {
          processVoiceCommand(finalTranscript, bestConfidence);
        }
      };
      
      recognition.onerror = (event) => {
        console.error('‚ùå Web Speech error:', event.error);
        setIsListening(false);
        if (onError) {
          onError(new Error(`Speech recognition error: ${event.error}`));
        }
      };
      
      recognition.onend = () => {
        console.log('üèÅ Web Speech recognition ended');
        setIsListening(false);
      };
      
      recognitionRef.current = recognition;
    } else {
      console.warn('‚ö†Ô∏è Web Speech API not supported');
    }
    
    return () => {
      if (recognitionRef.current) {
        recognitionRef.current.stop();
      }
    };
  }, [onTranscript, onError]);

  // Audio level monitoring
  const startAudioMonitoring = useCallback(async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          sampleRate: 44100
        }
      });
      
      micStreamRef.current = stream;
      
      const audioContext = new (window.AudioContext || window.webkitAudioContext)();
      const analyser = audioContext.createAnalyser();
      const microphone = audioContext.createMediaStreamSource(stream);
      
      analyser.fftSize = 256;
      microphone.connect(analyser);
      
      audioContextRef.current = audioContext;
      analyserRef.current = analyser;
      
      // Start audio level animation
      const dataArray = new Uint8Array(analyser.frequencyBinCount);
      
      const updateAudioLevel = () => {
        if (analyserRef.current && isListening) {
          analyserRef.current.getByteFrequencyData(dataArray);
          const level = dataArray.reduce((sum, value) => sum + value, 0) / dataArray.length;
          setAudioLevel(level / 255);
          animationRef.current = requestAnimationFrame(updateAudioLevel);
        }
      };
      
      updateAudioLevel();
      
    } catch (error) {
      console.error('‚ùå Audio monitoring failed:', error);
    }
  }, [isListening]);

  // Stop audio monitoring
  const stopAudioMonitoring = useCallback(() => {
    if (animationRef.current) {
      cancelAnimationFrame(animationRef.current);
    }
    
    if (micStreamRef.current) {
      micStreamRef.current.getTracks().forEach(track => track.stop());
    }
    
    if (audioContextRef.current) {
      audioContextRef.current.close();
    }
    
    setAudioLevel(0);
  }, []);

  // Process voice command
  const processVoiceCommand = useCallback((text, confidence) => {
    const normalizedText = text.toLowerCase().trim();
    console.log('üß† Processing command:', normalizedText, `(${Math.round(confidence * 100)}% confidence)`);
    
    // Detect intent
    let intent = 'unknown';
    let entities = {};
    
    // Check for known command patterns
    for (const [intentKey, patterns] of Object.entries(CROATIAN_VOICE_COMMANDS)) {
      if (patterns.some(pattern => normalizedText.includes(pattern))) {
        intent = intentKey;
        break;
      }
    }
    
    // Extract entities based on intent
    if (intent === 'send' || intent === 'select') {
      // Extract document name or number
      let afterCommand = normalizedText
        .replace(/po≈°alji|posalji|≈°alji|salji|uploadaj|obradi|odaberi|izaberi|naƒëi|pronadi/g, '')
        .trim();
      
      // Convert spoken extensions to proper format
      // "testni pdf" -> "testni.pdf", "dokument word" -> "dokument.doc", etc.
      afterCommand = afterCommand
        .replace(/\s+(pdf|p d f)$/i, '.pdf')
        .replace(/\s+(doc|word|dokument)$/i, '.doc') 
        .replace(/\s+(docx|word dokument)$/i, '.docx')
        .replace(/\s+(xlsx|excel|tabela)$/i, '.xlsx')
        .replace(/\s+(txt|tekst)$/i, '.txt')
        .replace(/\s+(jpg|jpeg|slika)$/i, '.jpg')
        .replace(/\s+(png|p n g)$/i, '.png');
      
      console.log(`üìù Document name processing: "${normalizedText}" -> "${afterCommand}"`);
      
      if (afterCommand) {
        entities.documentName = afterCommand;
      }
      
      // Check for "newest" keyword
      if (CROATIAN_VOICE_COMMANDS.newest.some(pattern => normalizedText.includes(pattern))) {
        entities.useNewest = true;
      }
      
      // Extract numbers (for "ponuda 001", "raƒçun 123", etc.)
      const numberMatch = afterCommand.match(/\d+/);
      if (numberMatch) {
        entities.number = numberMatch[0];
      }
    }
    
    const command = {
      text: normalizedText,
      originalText: text,
      intent,
      entities,
      confidence,
      timestamp: new Date().toISOString()
    };
    
    setLastCommand(command);
    
    if (onCommand) {
      onCommand(command);
    }
    
    console.log('‚úÖ Command processed:', command);
  }, [onCommand]);

  // Initialize OpenAI Realtime
  const initializeRealtime = useCallback(async () => {
    try {
      setIsProcessing(true);
      
      // Get ephemeral token from our server
      const tokenResponse = await fetch('/api/agent/voice-token', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' }
      });
      
      if (!tokenResponse.ok) {
        throw new Error('Failed to get Realtime token');
      }
      
      const session = await tokenResponse.json();
      console.log('üîë Realtime session created:', session);
      
      // Initialize WebRTC connection
      // Note: This is a placeholder for the actual Realtime API WebRTC implementation
      // The full implementation would involve:
      // 1. Creating RTCPeerConnection
      // 2. Setting up audio tracks
      // 3. Establishing connection with OpenAI Realtime endpoint
      // 4. Handling audio streaming bidirectionally
      
      setRealtimeConnected(true);
      setMode('realtime');
      
      console.log('‚úÖ Realtime API connected');
      
    } catch (error) {
      console.error('‚ùå Realtime initialization failed:', error);
      setRealtimeConnected(false);
      setMode('webspeech');
      
      if (onError) {
        onError(new Error(`Realtime API failed: ${error.message}. Falling back to Web Speech.`));
      }
    } finally {
      setIsProcessing(false);
    }
  }, [onError]);

  // Start listening
  const startListening = useCallback(async () => {
    if (disabled || isListening) return;
    
    setTranscript('');
    setLastCommand(null);
    
    if (mode === 'realtime' && realtimeConnected) {
      // Start Realtime listening
      console.log('üé§ Starting Realtime listening...');
      setIsListening(true);
      await startAudioMonitoring();
    } else if (mode === 'webspeech' && recognitionRef.current) {
      // Start Web Speech
      try {
        recognitionRef.current.start();
        await startAudioMonitoring();
      } catch (error) {
        console.error('‚ùå Failed to start Web Speech:', error);
        if (onError) {
          onError(error);
        }
      }
    }
  }, [disabled, isListening, mode, realtimeConnected, startAudioMonitoring, onError]);

  // Stop listening
  const stopListening = useCallback(() => {
    if (mode === 'realtime') {
      // Stop Realtime
      console.log('‚èπÔ∏è Stopping Realtime listening...');
    } else if (recognitionRef.current) {
      // Stop Web Speech
      recognitionRef.current.stop();
    }
    
    setIsListening(false);
    stopAudioMonitoring();
  }, [mode, stopAudioMonitoring]);

  // Toggle listening
  const toggleListening = useCallback(() => {
    if (isListening) {
      stopListening();
    } else {
      startListening();
    }
  }, [isListening, startListening, stopListening]);

  // Speak text (Croatian TTS)
  const speak = useCallback((text) => {
    if ('speechSynthesis' in window) {
      const utterance = new SpeechSynthesisUtterance(text);
      utterance.lang = 'hr-HR';
      utterance.rate = 0.9;
      utterance.pitch = 1.0;
      speechSynthesis.speak(utterance);
    }
  }, []);

  // Audio visualization bars
  const renderAudioBars = () => {
    return (
      <div className="flex items-center justify-center space-x-1 h-8">
        {[...Array(5)].map((_, i) => (
          <div
            key={i}
            className={`w-1 bg-blue-400 rounded-full transition-all duration-150 ${
              isListening ? 'animate-pulse' : ''
            }`}
            style={{
              height: `${Math.max(4, audioLevel * 32 + Math.random() * 8)}px`,
              animationDelay: `${i * 0.1}s`
            }}
          />
        ))}
      </div>
    );
  };

  return (
    <div className="voice-hr-container bg-white rounded-xl p-6 border border-gray-200 shadow-lg">
      {/* Header */}
      <div className="flex items-center justify-between mb-4">
        <div className="flex items-center gap-2">
          <h3 className="text-lg font-semibold text-gray-900">Hrvatski glasovni unos</h3>
          <div className={`w-2 h-2 rounded-full ${realtimeConnected ? 'bg-green-500' : 'bg-yellow-500'}`} />
        </div>
        
        <div className="flex items-center gap-2">
          <select
            value={mode}
            onChange={(e) => setMode(e.target.value)}
            className="text-sm border border-gray-300 rounded px-2 py-1"
            disabled={isListening}
          >
            <option value="webspeech">Web Speech</option>
            <option value="realtime">OpenAI Realtime</option>
          </select>
          
          {mode === 'realtime' && !realtimeConnected && (
            <button
              onClick={initializeRealtime}
              disabled={isProcessing}
              className="text-sm bg-blue-500 text-white px-3 py-1 rounded hover:bg-blue-600 disabled:opacity-50"
            >
              {isProcessing ? <Loader className="w-3 h-3 animate-spin" /> : 'Connect'}
            </button>
          )}
        </div>
      </div>

      {/* Main Voice Button */}
      <div className="flex flex-col items-center space-y-4">
        <button
          onClick={toggleListening}
          disabled={disabled || (mode === 'realtime' && !realtimeConnected)}
          className={`relative w-20 h-20 rounded-full text-white text-2xl transition-all duration-200 shadow-lg hover:shadow-xl disabled:opacity-50 disabled:cursor-not-allowed ${
            isListening 
              ? 'bg-red-500 hover:bg-red-600 animate-pulse' 
              : isProcessing
              ? 'bg-gray-400'
              : 'bg-blue-500 hover:bg-blue-600'
          }`}
        >
          {isProcessing ? (
            <Loader className="w-8 h-8 animate-spin mx-auto" />
          ) : isListening ? (
            <MicOff className="w-8 h-8 mx-auto" />
          ) : (
            <Mic className="w-8 h-8 mx-auto" />
          )}
          
          {/* Audio level ring */}
          {isListening && (
            <div 
              className="absolute inset-0 rounded-full border-4 border-white opacity-30"
              style={{
                transform: `scale(${1 + audioLevel * 0.3})`,
                transition: 'transform 0.1s ease-out'
              }}
            />
          )}
        </button>

        {/* Audio visualization */}
        {renderAudioBars()}

        {/* Status text */}
        <div className="text-center">
          {isProcessing && (
            <p className="text-gray-600 text-sm animate-pulse">
              Uspostavljam vezu...
            </p>
          )}
          {isListening && !isProcessing && (
            <p className="text-red-600 text-sm font-medium">
              üî¥ Slu≈°am... (kliknite za stop)
            </p>
          )}
          {!isListening && !isProcessing && (
            <p className="text-gray-600 text-sm">
              Kliknite za snimanje glasovne naredbe
            </p>
          )}
        </div>
      </div>

      {/* Transcript Display */}
      {transcript && (
        <div className="mt-4 p-3 bg-gray-50 rounded-lg border-l-4 border-blue-400">
          <div className="flex items-start justify-between">
            <div className="flex-1">
              <h4 className="font-medium text-gray-800 text-sm mb-1">Prepoznato:</h4>
              <p className="text-gray-700">{transcript}</p>
            </div>
            {confidence > 0 && (
              <div className="ml-2 text-xs text-gray-500">
                {Math.round(confidence * 100)}%
              </div>
            )}
          </div>
        </div>
      )}

      {/* Last Command */}
      {lastCommand && (
        <div className="mt-3 p-3 bg-blue-50 rounded-lg border-l-4 border-blue-500">
          <div className="flex items-start justify-between">
            <div className="flex-1">
              <h4 className="font-medium text-blue-800 text-sm mb-1">Naredba:</h4>
              <div className="text-blue-700 text-sm space-y-1">
                <p><strong>Intent:</strong> {lastCommand.intent}</p>
                {Object.keys(lastCommand.entities).length > 0 && (
                  <p><strong>Podaci:</strong> {JSON.stringify(lastCommand.entities)}</p>
                )}
              </div>
            </div>
            <div className="ml-2 text-xs text-blue-500">
              {Math.round(lastCommand.confidence * 100)}%
            </div>
          </div>
        </div>
      )}

      {/* Help Text */}
      <div className="mt-4 bg-blue-50 p-3 rounded-lg border border-blue-200">
        <h4 className="font-medium text-blue-900 text-sm mb-2">üí° Primjeri naredbi:</h4>
        <div className="text-blue-800 text-xs space-y-1">
          <p><strong>Slanje:</strong> "po≈°alji ponudu 001", "obradi testnik.pdf"</p>
          <p><strong>Odabir:</strong> "odaberi raƒçun 123", "naƒëi najnoviji dokument"</p>
          <p><strong>Potvrda:</strong> "jasan zvuk", "potvrdi", "da"</p>
          <p><strong>Otkazivanje:</strong> "poni≈°ti", "stop"</p>
        </div>
      </div>
    </div>
  );
}